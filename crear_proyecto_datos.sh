#!/bin/bash

# Script para crear estructura de carpetas para proyecto de anÃ¡lisis de datos
# Autor: Script generado para anÃ¡lisis de datos
# Fecha: $(date +%Y-%m-%d)

# Colores para output
RED='\033[0;31m'
GREEN='\033[0;32m'
BLUE='\033[0;34m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

echo -e "${BLUE}=== Creando estructura de proyecto de anÃ¡lisis de datos ===${NC}"

# Obtener nombre del proyecto
read -p "Ingresa el nombre del proyecto (por defecto: mi_proyecto_datos): " PROJECT_NAME
PROJECT_NAME=${PROJECT_NAME:-mi_proyecto_datos}

# Crear directorio principal del proyecto
if [ -d "$PROJECT_NAME" ]; then
    echo -e "${YELLOW}Â¡Advertencia! El directorio '$PROJECT_NAME' ya existe.${NC}"
    read -p "Â¿Deseas continuar? Los archivos existentes no se sobrescribirÃ¡n (y/n): " CONTINUE
    if [ "$CONTINUE" != "y" ] && [ "$CONTINUE" != "Y" ]; then
        echo -e "${RED}OperaciÃ³n cancelada.${NC}"
        exit 1
    fi
fi

mkdir -p "$PROJECT_NAME"
cd "$PROJECT_NAME"

echo -e "${GREEN}âœ“${NC} Creando estructura en: $(pwd)"

# Crear estructura de carpetas
echo -e "${BLUE}Creando directorios...${NC}"

# Carpetas principales
mkdir -p data/{raw,processed,external,interim}
mkdir -p notebooks/{exploratory,final}
mkdir -p src/{data,features,models,visualization}
mkdir -p models/{trained,evaluation}
mkdir -p reports/{figures,presentations,documents}
mkdir -p config
mkdir -p tests
mkdir -p docs
mkdir -p scripts
mkdir -p logs

echo -e "${GREEN}âœ“${NC} Estructura de carpetas creada"

# Crear archivos README para cada carpeta principal
echo -e "${BLUE}Creando archivos README...${NC}"

# README principal
cat > README.md << 'EOF'
# Proyecto de AnÃ¡lisis de Datos

## DescripciÃ³n del Proyecto
Breve descripciÃ³n de tu proyecto de anÃ¡lisis de datos.

## Estructura del Proyecto
```
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/           # Datos originales, inmutables
â”‚   â”œâ”€â”€ processed/     # Datos limpios y procesados
â”‚   â”œâ”€â”€ external/      # Datos de fuentes externas
â”‚   â””â”€â”€ interim/       # Datos intermedios durante procesamiento
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ exploratory/   # AnÃ¡lisis exploratorio
â”‚   â””â”€â”€ final/         # Notebooks finales
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/          # Scripts para descargar/generar datos
â”‚   â”œâ”€â”€ features/      # Scripts para feature engineering
â”‚   â”œâ”€â”€ models/        # Scripts para entrenar modelos
â”‚   â””â”€â”€ visualization/ # Scripts para crear visualizaciones
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ trained/       # Modelos entrenados
â”‚   â””â”€â”€ evaluation/    # MÃ©tricas y evaluaciones
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ figures/       # GrÃ¡ficos y figuras
â”‚   â”œâ”€â”€ presentations/ # Presentaciones
â”‚   â””â”€â”€ documents/     # Reportes en PDF, Word, etc.
â”œâ”€â”€ config/            # Archivos de configuraciÃ³n
â”œâ”€â”€ tests/             # Tests unitarios
â”œâ”€â”€ docs/              # DocumentaciÃ³n
â”œâ”€â”€ scripts/           # Scripts de automatizaciÃ³n
â””â”€â”€ logs/              # Archivos de log
```

## InstalaciÃ³n y Uso
1. Clona este repositorio
2. Instala las dependencias: `pip install -r requirements.txt`
3. Ejecuta los notebooks en orden numÃ©rico

## ContribuciÃ³n
Describe cÃ³mo otros pueden contribuir al proyecto.
EOF

# README para data
cat > data/README.md << 'EOF'
# Directorio de Datos

## Estructura:
- **raw/**: Datos originales, nunca modificar estos archivos
- **processed/**: Datos limpios listos para anÃ¡lisis
- **external/**: Datos de fuentes externas (APIs, bases de datos)
- **interim/**: Datos intermedios durante el procesamiento

## Convenciones:
- Usar nombres descriptivos para los archivos
- Incluir fecha en el nombre si es relevante
- Mantener un registro de la fuente de los datos
EOF

# README para notebooks
cat > notebooks/README.md << 'EOF'
# Notebooks

## Estructura:
- **exploratory/**: AnÃ¡lisis exploratorio de datos (EDA)
- **final/**: Notebooks finales y limpios para presentaciÃ³n

## Convenciones de nomenclatura:
- Usar nÃºmeros para orden: 01_exploration.ipynb, 02_modeling.ipynb
- Nombres descriptivos y en inglÃ©s o espaÃ±ol consistentemente
- Mantener notebooks limpios y bien documentados
EOF

# README para src
cat > src/README.md << 'EOF'
# CÃ³digo Fuente

## Estructura:
- **data/**: Scripts para adquisiciÃ³n y procesamiento de datos
- **features/**: Scripts para feature engineering
- **models/**: Scripts para entrenamiento y predicciÃ³n
- **visualization/**: Scripts para generar visualizaciones

## Convenciones:
- Funciones bien documentadas
- CÃ³digo modular y reutilizable
- Tests para funciones crÃ­ticas
EOF

# README para reports
cat > reports/README.md << 'EOF'
# Reportes y Resultados

## Estructura:
- **figures/**: GrÃ¡ficos, plots y visualizaciones
- **presentations/**: Presentaciones PowerPoint, PDF
- **documents/**: Reportes tÃ©cnicos, papers

## Convenciones:
- Usar nombres descriptivos
- Incluir fecha de generaciÃ³n
- Mantener versiones de figuras importantes
EOF

echo -e "${GREEN}âœ“${NC} Archivos README creados"

# Crear archivos de configuraciÃ³n bÃ¡sicos
echo -e "${BLUE}Creando archivos de configuraciÃ³n...${NC}"

# requirements.txt
cat > requirements.txt << 'EOF'
# AnÃ¡lisis de datos
pandas>=1.5.0
numpy>=1.24.0
scipy>=1.10.0

# VisualizaciÃ³n
matplotlib>=3.6.0
seaborn>=0.12.0
plotly>=5.17.0

# Machine Learning
scikit-learn>=1.3.0
xgboost>=1.7.0

# Jupyter
jupyter>=1.0.0
ipykernel>=6.25.0

# Utilidades
python-dotenv>=1.0.0
pyyaml>=6.0
tqdm>=4.66.0

# Testing
pytest>=7.4.0
EOF

# .gitignore
cat > .gitignore << 'EOF'
# Byte-compiled / optimized / DLL files
__pycache__/
*.py[cod]
*$py.class

# C extensions
*.so

# Distribution / packaging
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# PyInstaller
*.manifest
*.spec

# Installer logs
pip-log.txt
pip-delete-this-directory.txt

# Unit test / coverage reports
htmlcov/
.tox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
.hypothesis/
.pytest_cache/

# Jupyter Notebook
.ipynb_checkpoints

# pyenv
.python-version

# Environment variables
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# IDEs
.vscode/
.idea/
*.swp
*.swo
*~

# OS
.DS_Store
.DS_Store?
._*
.Spotlight-V100
.Trashes
ehthumbs.db
Thumbs.db

# Data files (uncomment if you don't want to track large data files)
# *.csv
# *.xlsx
# *.json
# *.pkl
# *.h5

# Model files
*.joblib
*.pkl
*.h5
*.hdf5

# Log files
*.log
logs/*.log
EOF

# Archivo de configuraciÃ³n bÃ¡sico
cat > config/config.yaml << 'EOF'
# ConfiguraciÃ³n del proyecto
project:
  name: "Mi Proyecto de Datos"
  version: "1.0.0"
  description: "AnÃ¡lisis de datos con Python"

# Rutas de datos
data:
  raw: "data/raw/"
  processed: "data/processed/"
  external: "data/external/"
  interim: "data/interim/"

# ConfiguraciÃ³n de modelos
models:
  output_dir: "models/trained/"
  evaluation_dir: "models/evaluation/"

# ConfiguraciÃ³n de reportes
reports:
  figures_dir: "reports/figures/"
  output_dir: "reports/documents/"

# Logging
logging:
  level: "INFO"
  file: "logs/project.log"
EOF

# Script bÃ¡sico de setup
cat > scripts/setup.py << 'EOF'
#!/usr/bin/env python3
"""
Script de configuraciÃ³n inicial del proyecto
"""

import os
import sys
from pathlib import Path

def setup_environment():
    """Configura el entorno inicial del proyecto"""
    
    # Crear directorios adicionales si no existen
    dirs_to_create = [
        'logs',
        'models/trained',
        'models/evaluation',
        'reports/figures',
        'data/raw',
        'data/processed'
    ]
    
    for dir_path in dirs_to_create:
        Path(dir_path).mkdir(parents=True, exist_ok=True)
        print(f"âœ“ Directorio creado/verificado: {dir_path}")
    
    print("\nâœ… ConfiguraciÃ³n inicial completada!")
    print("ðŸ“‹ PrÃ³ximos pasos:")
    print("1. Instalar dependencias: pip install -r requirements.txt")
    print("2. Agregar tus datos en data/raw/")
    print("3. Comenzar con notebooks/exploratory/")

if __name__ == "__main__":
    setup_environment()
EOF

chmod +x scripts/setup.py

echo -e "${GREEN}âœ“${NC} Archivos de configuraciÃ³n creados"

# Crear algunos archivos ejemplo
echo -e "${BLUE}Creando archivos ejemplo...${NC}"

# Notebook ejemplo
cat > notebooks/exploratory/00_template_exploration.ipynb << 'EOF'
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AnÃ¡lisis Exploratorio de Datos - Template\n",
    "\n",
    "## Objetivo\n",
    "Describir el objetivo de este anÃ¡lisis\n",
    "\n",
    "## Dataset\n",
    "Describir el dataset utilizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerÃ­as\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ConfiguraciÃ³n\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos\n",
    "# df = pd.read_csv('../data/raw/tu_archivo.csv')\n",
    "# df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
EOF

# Script ejemplo para procesamiento de datos
cat > src/data/data_processing.py << 'EOF'
"""
MÃ³dulo para procesamiento de datos
"""

import pandas as pd
import numpy as np
from pathlib import Path

def load_raw_data(filename):
    """
    Carga datos desde la carpeta raw
    
    Args:
        filename (str): Nombre del archivo
        
    Returns:
        pandas.DataFrame: Datos cargados
    """
    filepath = Path("data/raw") / filename
    
    if filename.endswith('.csv'):
        return pd.read_csv(filepath)
    elif filename.endswith('.xlsx'):
        return pd.read_excel(filepath)
    else:
        raise ValueError("Formato de archivo no soportado")

def clean_data(df):
    """
    FunciÃ³n bÃ¡sica de limpieza de datos
    
    Args:
        df (pandas.DataFrame): DataFrame a limpiar
        
    Returns:
        pandas.DataFrame: DataFrame limpio
    """
    # Eliminar duplicados
    df_clean = df.drop_duplicates()
    
    # AquÃ­ agregar mÃ¡s pasos de limpieza segÃºn necesidad
    
    return df_clean

def save_processed_data(df, filename):
    """
    Guarda datos procesados
    
    Args:
        df (pandas.DataFrame): DataFrame a guardar
        filename (str): Nombre del archivo
    """
    filepath = Path("data/processed") / filename
    df.to_csv(filepath, index=False)
    print(f"Datos guardados en: {filepath}")

if __name__ == "__main__":
    # Ejemplo de uso
    print("MÃ³dulo de procesamiento de datos listo para usar")
EOF

echo -e "${GREEN}âœ“${NC} Archivos ejemplo creados"

# Crear un archivo de log inicial
touch logs/project.log
echo "$(date): Proyecto '$PROJECT_NAME' creado exitosamente" > logs/project.log

# Mostrar resumen
echo -e "\n${GREEN}ðŸŽ‰ Â¡Estructura del proyecto creada exitosamente! ðŸŽ‰${NC}"
echo -e "\n${BLUE}ðŸ“ Estructura creada:${NC}"
tree -L 3 2>/dev/null || find . -type d | sort

echo -e "\n${YELLOW}ðŸ“‹ PrÃ³ximos pasos recomendados:${NC}"
echo "1. cd $PROJECT_NAME"
echo "2. python scripts/setup.py"
echo "3. pip install -r requirements.txt"
echo "4. Agrega tus datos en data/raw/"
echo "5. Comienza tu anÃ¡lisis en notebooks/exploratory/"

echo -e "\n${GREEN}âœ¨ Â¡Listo para comenzar tu proyecto de anÃ¡lisis de datos! âœ¨${NC}"